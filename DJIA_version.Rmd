---
title: "honors_thesis"
author: "Georges Ip"
date: "3/1/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE}
#Import libraries
library(lattice)
library(MASS)
library(car)
require(stats)
require(stats4)
library(KernSmooth)
library(cluster)
library(leaps)
library(mgcv)
library(rpart)
library(mgcv)
require("datasets")
require(graphics)
library(nlstools)
library(fpp)
library(fpp2)
library(strucchange)
library(Quandl)
library(zoo)
library(PerformanceAnalytics)
library(quantmod)
library(vars)
library(lmtest)
library(tseries)
library(dplyr)
library(lubridate)
library(TTR)
library(repmis)
library(readr)
library(SentimentAnalysis)
library(readxl)
library(tidytext)
library(wordcloud)
library(doParallel)
library(caret)
library(imputeTS)
library(randomForest)
library(gbm)
library(kernlab)
library(e1071)
library(devtools)
library(remotes)
#remotes::install_github("trinker/sentimentr")
library(sentimentr)
library(tidyverse)
library(tm)
library(rJava)
library(coreNLP)
library(syuzhet)
library(qdap)
library(DMwR)
```

Main stock dataset
```{r message=FALSE}
#Using quantmod
getSymbols("^DJI", src = "yahoo", from = as.Date("2009-01-01"), to = as.Date("2019-12-31"))
DJIA<-DJI
#Add columns for returns
#frist create a name vector for new returns
names <- c("DJI.Open.returns", "DJI.High.returns", "DJI.Low.returns", "DJI.Close.returns", "DJI.Volume.returns", "DJI.Adjusted.returns")
returns.data<-ROC(DJIA)
names(returns.data) <- names
#Drop volume returns as it is not applicable in this case
returns.data <- subset(returns.data, select = -c(5))
#now combine the two datasets
DJIA<-merge(DJIA,returns.data,join='left') 
#Take first difference
DJIA$diff <- DJIA$DJI.Close - Lag(DJIA$DJI.Close)
#Convert difference into output vector
DJIA$direction <- ifelse(DJIA$diff  > 0, 1, 0)
#DJIA$direction <- as.factor(DJIA$direction)
```

Technical Indicators (1)
```{r}
#implement a simple 10 day moving average
DJIA$SMA10 <- SMA(DJIA$DJI.Close, n = 10)
#implement a weighted 10 day moving average
DJIA$WMA10 <- WMA(DJIA$DJI.Adjusted, n = 10, wts = 1:10)
#Implement momentum, the amount the price has changed over the last n periods
momentum = diff(DJIA$DJI.Adjusted, lag = 4, differences = 1)
DJIA$momentum <- momentum
#Implement stochastic K%, another indicator comparing the closing price of an asset to a range of its prices over a certain period of time n.
#We choose n = 14 for now
DJIA$stochastic.k <- stoch(DJIA[,c("DJI.High","DJI.Low", "DJI.Adjusted")], nFastK = 14, bounded = TRUE)*100
#Implement stochastic D%, which is the 3-day mooving average of K%
DJIA$stochastic.d <- stoch(DJIA[,c("DJI.High","DJI.Low", "DJI.Adjusted")],  nFastD = 3, bounded = TRUE)*100
#This duplicates fast d and fast k, so let's remove those
drops <- c("fastK.1", "fastD.1")
DJIA<-DJIA[ , !(names(DJIA) %in% drops)]
#Implement RSI, the relative strength index. RSI is a measure of ratio of the recent upward price movements to the absolute price movement
#We will use n=14 for now
DJIA$RSI <- RSI(DJIA$DJI.Adjusted, n = 14)
#Implement MACD, moving average convergence divergence. This is another oscillator indicator that utilizes exponential moving averages to chart thet trend of price movements 
DJIA$MACD <- MACD(DJIA[,"DJI.Close"], 12, 26, 9, maType = "EMA")
#Implement Larry Williamâ€™s R%. This is a momentum indicator that tracks overbought and oversold levels. It is quite similar to the stochastic K%.
DJIA$Williams.R <- WPR(DJIA[,c("DJI.High","DJI.Low", "DJI.Close")])
#Implement the A/D (Accumulation/Distribution) Oscillator is an indicator that aims to measure bullish and bearish price pressure. 
DJIA$Williams.AD <- williamsAD(DJIA[,c("DJI.High","DJI.Low", "DJI.Close")])
#Implement the CCI (Commodity Channel Index). The CCI is another momentum indicator that is used to determine when an asset is reaching overbought or oversold conditions. 
DJIA$CCI <- CCI(DJIA[,c("DJI.High","DJI.Low", "DJI.Close")], n = 3, maType = "SMA", c = 0.015)
```

Technical Indicators (2)
```{r}
#Implement OBV, On Balance Volume. OBV is a momentum indicator that tracks changes in volume traded as well as price. 
DJIA$OBV <- OBV(DJIA[,"DJI.Close"], DJIA[,"DJI.Volume"])
#Implement a 5 period simple moving average
DJIA$SMA5 <- SMA(DJIA$DJI.Adjusted, n = 5)
#Implement a 6 period bias indicator. This indicator derives a directional bias relative tot he 6 period moving average value
SMA6 <- SMA(DJIA$DJI.Adjusted, n = 6)
DJIA$BIAS6 <- (DJIA$DJI.Adjusted - SMA6)/SMA6 * 100
#Implement PSY12, which measures the ratio of rising periods over the last 12 periods
DJIA$PSY12 <- rep(NA,nrow(DJIA))
for(i in 12:nrow(DJIA)){
DJIA$PSY12[i] <- sum(DJIA$direction[(i-11):i]) /12 *100
}
#Implement ASYn, which is the average return over the past n periods
DJIA$ASY1 <- lag(DJIA$DJI.Close.returns, n=1)
DJIA$ASY2 <- SMA(DJIA$DJI.Close.returns, n =2)
DJIA$ASY3 <- SMA(DJIA$DJI.Close.returns, n =3)
DJIA$ASY4 <- SMA(DJIA$DJI.Close.returns, n =4)
DJIA$ASY5 <- SMA(DJIA$DJI.Close.returns, n =5)
```

Fundamental Indicators
```{r message=FALSE}
#Import the China-US exchange rate
USCHEX <- source_data("https://raw.githubusercontent.com/georgesip/financial_engineering/master/DEXCHUS-edited.csv")
USCHEX <- head(USCHEX, -1)
#Combine it with the DJIA dataset
DJIA$USCHEX <- USCHEX$DEXCHUS
#Add SP500 indicator as another fundamental
#using quantmod
getSymbols("^GSPC",src = "yahoo", from = as.Date("2009-01-01"), to = as.Date("2019-12-31"))
GSPC.ret <- ROC(GSPC)
DJIA$GSPC.returns <- GSPC.ret$GSPC.Adjusted
```

Sentiment Indicators
```{r}
#Import dataset
news1 <- read_csv("2020-3-6-15-7-23-569723201808043-S&P 500 News - Investing.com-ScrapingData-ScrapeStorm.csv")
news2 <- read_excel("2020-3-7-20-35-11-59646935038951-S&P 500 News - Investing.com-ScrapingData-ScrapeStorm-2.xlsx")
news.1 <- head(news1, -1)
news.temp <- rbind(news.1,news2)
news.full<-news.temp
```
Preprocessing of sentiment
```{r}
#Clean the dataset
date.fill <- "- Mar 05, 2020"
news.full$date[1:33] <- date.fill
news.full$date <- gsub("- ", "", news.full$date)
news.full$date <- mdy(news.full$date)
drops <- c('Title_link','js-external-link', 'articleDetails')
news.full<-news.full[,!(names(news.full) %in% drops)]
#rearrange chronological order
news.full <- arrange(news.full, date)
#There are a few duplicated entries, let's remove them
news.full<-news.full %>%
    distinct(Title, date, .keep_all = TRUE)
#remove NA's 
news.full[is.na(news.full)] = "unknown"
```


Cleaning the dataset thoroughly for SentimentAnalysis package
```{r}
#clean the text itself from headlines
news.cleaned <- news.full
news.cleaned$Title <- tolower(news.cleaned$Title)
news.cleaned$Title <- gsub("global markets-", "",news.cleaned$Title)
news.cleaned$Title <- gsub("rpt-", "",news.cleaned$Title)
news.cleaned$Title <- gsub("-", " ",news.cleaned$Title)
news.cleaned$Title <- gsub("[[:punct:]]", " ", news.cleaned$Title)
#clean the text itself from description
news.cleaned$textDiv <- tolower(news.cleaned$textDiv)
news.cleaned$textDiv <- gsub("\\s*\\([^\\)]+\\)","",news.cleaned$textDiv)
news.cleaned$textDiv <- gsub("-", " ",news.cleaned$textDiv)
news.cleaned$textDiv <- gsub("[[:punct:]]", " ", news.cleaned$textDiv)
#crete alternate set wiitout stop words
news.full.alt <- news.full
stopWords <- stopwords("SMART")
news.full.alt$Title<- as.character(news.full.alt$Title) 
'%nin%' <- Negate('%in%')
news.full.alt$Title_clean<-lapply(news.full.alt$Title, function(x) {
  chk <- unlist(strsplit(x," "))
  p <- chk[chk %nin% stopWords]
  paste(p,collapse = " ")
})
news.full.alt$desc_clean<-lapply(news.full.alt$textDiv, function(x) {
  chk <- unlist(strsplit(x," "))
  p <- chk[chk %nin% stopWords]
  paste(p,collapse = " ")
})
```

Less thorough cleaning for the other packages that can handle sentence structure better
```{r}
news.unclean <- news.full #This alternative dataset is used for the other libraries as they can handle more advanced sentence structures
#clean the text itself from headlines
news.unclean$Title <- gsub("GLOBAL MARKETS-", "",news.unclean$Title)
news.unclean$Title <- gsub("RPT-", "",news.unclean$Title)
news.unclean$Title <- gsub("-", " ",news.unclean$Title)
news.unclean$Title <- gsub("[[:punct:]]", " ", news.unclean$Title)
#clean the text itself from description
news.unclean$textDiv <- gsub("\\s*\\([^\\)]+\\)","",news.unclean$textDiv)
news.unclean$textDiv <- gsub("-", " ",news.unclean$textDiv)
news.unclean$textDiv <- gsub("[[:punct:]]", " ", news.unclean$textDiv)
news.unclean$textDiv <- gsub("[*]", ".", news.unclean$textDiv)
```


Summary of data (fine-tune this)
```{r}
#Wordcloud
wordcloud(news.cleaned$Title,min.freq = 10,colors=brewer.pal(8, "Dark2"),random.color = TRUE,max.words = 500)
Title_clean.df <- as.character(news.cleaned.alt$Title_clean)
wordcloud(Title_clean.df,min.freq = 10,colors=brewer.pal(8, "Dark2"),random.color = TRUE,max.words = 500)
```

Convert to sentiment (using SentimentAnalysis package)
```{r}
data(DictionaryLM)
#For headlines
sentiment <- analyzeSentiment(news.cleaned$Title, language = "english", aggregate = news.cleaned$date)
title.sentimentLM <- sentiment$SentimentLM
title.sentimentHE <- sentiment$SentimentHE
news.cleaned <- cbind(news.cleaned, title.sentimentLM, title.sentimentHE)
#for descriptioin as a sanity check
sentiment2 <- analyzeSentiment(news.cleaned$textDiv, language = "english", aggregate = news.cleaned$date)
desc.sentimentLM <- sentiment2$SentimentLM
desc.sentimentHE <- sentiment2$SentimentHE
news.cleaned <- cbind(news.cleaned, desc.sentimentLM, desc.sentimentHE)
#Do the same for the alternate sentiment set
sentiment.alt <- analyzeSentiment(news.cleaned.alt$Title, language = "english", aggregate = news.cleaned.alt$date)
title.sentimentLM.alt <- sentiment.alt$SentimentLM
title.sentimentHE.alt <- sentiment.alt$SentimentHE
news.cleaned.alt <- cbind(news.cleaned.alt, title.sentimentLM.alt, title.sentimentHE.alt)
#for description as a sanity check
sentiment2.alt <- analyzeSentiment(news.cleaned.alt$textDiv, language = "english", aggregate = news.cleaned.alt$date)
desc.sentimentLM.alt <- sentiment2.alt$SentimentLM
desc.sentimentHE.alt <- sentiment2.alt$SentimentHE
news.cleaned.alt <- cbind(news.cleaned.alt, desc.sentimentLM.alt, desc.sentimentHE.alt)
```

It seems that when we run the sentiment analysis on the description, we obtain greater granular detail. Whereas the short length of the headlines results in multiple zero entries. (For the sentimentanalysis package).


```{r}
#We can also use the other packages to compare performance
#Use sentimentr package, which is an augmented dictionary lookup that takes valence shifters into account.
#work on the titles first
out.title <- with(
    news.unclean, 
    sentiment_by(
        get_sentences(Title), 
        date
    )
)
sentiment.ts <- xts(out.title$ave_sentiment, order.by=out.title$date)
plot(sentiment.ts)
#Now work on descriptions
out.desc <- with(
    news.unclean, 
    sentiment_by(
        get_sentences(textDiv), 
        date
    )
)
sentiment.desc.ts <- xts(out.desc$ave_sentiment, order.by=out.desc$date)
plot(sentiment.desc.ts)
#Another possible plot
highlight(out.title)
highlight(out.desc)
```

Now try adding the removed stopwords version to the model
```{r}
news.sentiment.title.LM.alt <- aggregate(news.cleaned.alt["title.sentimentLM.alt"], by=news.full["date"], mean)
news.sentiment.desc.LM.alt <- aggregate(news.cleaned.alt["desc.sentimentLM.alt"], by=news.full["date"], mean)
news.sentiment.title.HE.alt <- aggregate(news.cleaned.alt["title.sentimentHE.alt"], by=news.full["date"], mean)
news.sentiment.desc.HE.alt <- aggregate(news.cleaned.alt["desc.sentimentHE.alt"], by=news.full["date"], mean)

```
The non LD dictionary method has higher correlation weirdly


Integrate sentiment data with DJI (SentimentAnalysis)
```{r}
#First, group by date
news.sentiment.title.LM <- aggregate(news.cleaned["title.sentimentLM"], by=news.full["date"], mean)
news.sentiment.desc.LM <- aggregate(news.cleaned["desc.sentimentLM"], by=news.full["date"], mean)
news.sentiment.title.HE <- aggregate(news.cleaned["title.sentimentHE"], by=news.full["date"], mean)
news.sentiment.desc.HE <- aggregate(news.cleaned["desc.sentimentHE"], by=news.full["date"], mean)
DJIA.alt <- DJIA
for(i in 1:nrow(DJIA.alt)){
  if(any(as.Date.character(index(DJIA.alt)[i])==news.sentiment.title.LM$date)){
         title.sa.LM[i] <- news.sentiment.title.LM$title.sentimentLM[which(as.Date.character(index(DJIA.alt)[i])==news.sentiment.title.LM$date)]
  }
  if(any(as.Date.character(index(DJIA.alt)[i])==news.sentiment.desc.LM$date)){
         desc.sa.LM[i] <- news.sentiment.desc.LM$desc.sentimentLM[which(as.Date.character(index(DJIA.alt)[i])==news.sentiment.desc.LM$date)]
  }
}
DJIA.alt$title.sa.LM <- title.sa.LM
DJIA.alt$desc.sa.LM <- desc.sa.LM
#now with HE
for(i in 1:nrow(DJI)){
  if(any(as.Date.character(index(DJIA.alt)[i])==news.sentiment.title.HE$date)){
         title.sa.HE[i] <- news.sentiment.title.HE$title.sentimentHE[which(as.Date.character(index(DJIA.alt)[i])==news.sentiment.title.HE$date)]
  }
  if(any(as.Date.character(index(DJIA.alt)[i])==news.sentiment.desc.HE$date)){
         desc.sa.HE[i] <- news.sentiment.desc.HE$desc.sentimentHE[which(as.Date.character(index(DJIA.alt)[i])==news.sentiment.desc.HE$date)]
  }
}
DJIA.alt$title.sa.HE <- title.sa.HE
DJIA.alt$desc.sa.HE <- desc.sa.HE
```


Match SentimentAnalysis to DJI dataset based on date
```{r}
title.sa.LM <- rep(NA,nrow(DJIA))
title.sa.HE <- rep(NA,nrow(DJIA))
desc.sa.LM <- rep(NA,nrow(DJIA))
desc.sa.HE <- rep(NA,nrow(DJIA))

#Start with LM
for(i in 1:nrow(DJIA)){
  if(any(as.Date.character(index(DJIA)[i])==news.sentiment.title.LM$date)){
         title.sa.LM[i] <- news.sentiment.title.LM$title.sentimentLM[which(as.Date.character(index(DJIA)[i])==news.sentiment.title.LM$date)]
  }
  if(any(as.Date.character(index(DJIA)[i])==news.sentiment.desc.LM$date)){
         desc.sa.LM[i] <- news.sentiment.desc.LM$desc.sentimentLM[which(as.Date.character(index(DJIA)[i])==news.sentiment.desc.LM$date)]
  }
}
DJIA$title.sa.LM <- title.sa.LM
DJIA$desc.sa.LM <- desc.sa.LM
#now with HE
for(i in 1:nrow(DJI)){
  if(any(as.Date.character(index(DJIA)[i])==news.sentiment.title.HE$date)){
         title.sa.HE[i] <- news.sentiment.title.HE$title.sentimentHE[which(as.Date.character(index(DJIA)[i])==news.sentiment.title.HE$date)]
  }
  if(any(as.Date.character(index(DJIA)[i])==news.sentiment.desc.HE$date)){
         desc.sa.HE[i] <- news.sentiment.desc.HE$desc.sentimentHE[which(as.Date.character(index(DJIA)[i])==news.sentiment.desc.HE$date)]
  }
}
DJIA$title.sa.HE <- title.sa.HE
DJIA$desc.sa.HE <- desc.sa.HE
```


Implement sentiment from sentimentr into the dataset
```{r}
title.sr <- rep(NA,nrow(DJIA))
desc.sr <- rep(NA,nrow(DJIA))

for(i in 1:nrow(DJIA)){
  if(any(as.Date.character(index(DJIA)[i])==out.title$date)){
         title.sr[i] <- out.title$ave_sentiment[which(as.Date.character(index(DJIA)[i])==out.title$date)]
  }
  if(any(as.Date.character(index(DJIA)[i])==out.desc$date)){
         desc.sr[i] <- out.desc$ave_sentiment[which(as.Date.character(index(DJIA)[i])==out.desc$date)]
  }
  
}
DJIA$title.sr <- title.sr
DJIA$desc.sr <- desc.sr
```


We now look at plots of the data
```{r}
plot.zoo(DJIA$diff, xlab = "Month", ylab = "First difference of adjusted returns", col = 'blue', lwd = 0.5)
```
We can see that taking the first difference detrended the time series, and cetered it around zero. However, variance is still not constant, there is also clear signs of volatility clustering. However, we are focused on the direction of the time series, thus, the stationarity requirement is not as stringent. 


There are huge gaps in the news dataset
```{r}
#We first create another dataset with all the sentiment scores from all methods
keeps <- c("title.sa","desc.sa","title.sr","desc.sr")
sentiment_scores<-DJIA[ , (names(DJIA) %in% keeps)]
#Find the longest stretch
stretch <- na.contiguous(sentiment_scores)
#subset GSPC (missing news before 2014-03-25)
DJIA_full <- DJIA
DJIA <- DJIA[1315:2767,]
#There are still some NA's in USCHEX, we can do some imputation
colSums(is.na(DJIA))
DJIA <- na_locf(DJIA)
```


We have to offset our predictors as they are ordered time series. Hence, we aim to use predictors calculated at time t,to predict the direction at time t+1.
```{r}
#Remove non-relevant variables
DJIA.plot <- DJIA
drops <- c("DJI.Open","DJI.High","DJI.Low","DJI.Close","DJI.Volume","DJI.Adjusted","DJI.Open.returns","DJI.High.returns", "DJI.Low.returns","DJI.Close.returns", "DJI.Adjusted.returns", "diff")
DJIA<-DJIA[ , !(names(DJIA) %in% drops)]
#lag predictors by 1 day
test.case <- DJIA
for (i in 2:31){
  DJIA[,i] <- lag(DJIA[,i],1)
}
#Remove the first observation as we now have one row of NA's
DJIA <- DJIA[-1,]

#For the plotting dataframe
for (i in 14:43){
  DJIA.plot[,i] <- lag(DJIA.plot[,i],1)
}
#Remove the first observation as we now have one row of NA's
DJIA.plot <- DJIA.plot[-1,]
```

```{r}
#convert to dataframe for methods that require it
DJIA.df <- fortify.zoo(DJIA)
DJIA.df$direction <- as.factor(DJIA.df$direction)
levels(DJIA.df$direction) <- c("down", "up")
#scale the dataframe to [-1,1]
DJIA.scaled <- DJIA.df
DJIA.scaled$Index <- NULL
for (i in 2:31){
  DJIA.scaled[,i] <- LinearScaling(DJIA.scaled[,i])
}
```

Coorelation matrix
```{r}
#Time series
#First, add back in the difference 
plot.zoo(DJIA.plot$diff, xlab = "Month", ylab = "First difference of adjusted returns", col = 'blue', lwd = 0.5)
#Correlation heatmap
corr.df <- subset(DJIA.plot, select = -c(DJI.Open,DJI.High,DJI.Low,DJI.Close,DJI.Volume,DJI.Adjusted,DJI.Open.returns,DJI.High.returns, DJI.Low.returns,DJI.Close.returns,DJI.Adjusted.returns))
corr <- round(cor(corr.df),1)
library(ggcorrplot)
ggcorrplot(corr, tl.cex = 3)
```


We then perform a test for granger causality between the difference and our different fundamental and sentiment variables
```{r}
#For DJIA with DJI
keeps <- c("DJI.Close.returns","GSPC.returns")
DJIA.granger.1 <-DJIA_full[ ,(names(DJIA_full) %in% keeps)]
DJIA.granger.1 <- DJIA.granger.1[-1,]
VARselect(DJIA.granger.1, lag.max = 7)
grangertest(DJI.Close.returns~GSPC.returns, order = 1, data=DJIA_full)
grangertest(GSPC.returns~DJI.Close.returns, order = 2, data=DJIA_full)
#For sentiment with DJI
grangertest(diff~GSPC.returns, order = 4, data=DJIA_full)
grangertest(GSPC.returns~diff, order = 1, data=DJIA.plot)
#plot
plot(DJIA.plot$DJI.Close.returns)
lines(DJIA.plot$GSPC.returns, col = "red")
```
It is evident that for sentiment scores constructed from headlines, the difference in prices granger causes sentiment.


```{r}
grangertest(diff~DJI_sentiment_desc, order = 1, data=DJI)
grangertest(DJI_sentiment_desc~diff, order = 1, data=DJI)
```


The first dataset will be the full one with all variables included
```{r}
#Assess the number of NA's
colSums(is.na(DJIA.scaled))
#Split into training and test set
DJIA.end <- floor(0.9*nrow(DJIA.scaled)) #select the first 90% of the data
DJIA.train <- DJIA.scaled[1:DJIA.end,] #assign the first 90% of the data to the train set
DJIA.test <- DJIA.scaled[(DJIA.end+1):nrow(DJIA.scaled),]
```


Create dataset for technical indicators (1) only, without sentiment and fundamentals
```{r}
DJIA.t1 <- DJIA.scaled
keepst1 <- c("direction","SMA10", "WMA10","momentum","fastK","fastD", "stochastic.k","stochastic.d","RSI","macd","Williams.R","Williams.AD", "CCI", "USCHEX", "GSPC.returns", "title.sa.LM", "desc.sa.LM", "title.sa.HE", "desc.sa.HE", "title.sr", "desc.sr")
DJIA.t1<-DJIA.t1[ , (names(DJIA.t1) %in% keepst1)]
#Split into training and test set
DJIA.train.t1 <- DJIA.t1[1:DJIA.end,] #assign the first 80% of the data to the train set
DJIA.test.t1 <- DJIA.t1[(DJIA.end+1):nrow(DJIA.t1),]
```



Create dataset for technical indicators (2), with sentiment and fundamentals
```{r}
DJIA.t2 <- DJIA.scaled
keepst2 <- c("SMA10", "WMA10","momentum","fastK","fastD", "stochastic.k","stochastic.d","RSI","macd","Williams.R","Williams.AD", "CCI")
DJIA.t2<-DJIA.t2[ , !(names(DJIA.t2) %in% keepst2)]
#Split into training and test set
DJIA.train.t2 <- DJIA.t2[1:DJIA.end,] #assign the first 80% of the data to the train set
DJIA.test.t2 <- DJIA.t2[(DJIA.end+1):nrow(DJIA.t2),]
```


Create dataset with fundamentals only
```{r}

```

Create dataset with only sentiment
```{r}

```


We cannot perform the usual resampling methods such as LOOCV or k-fold CV as our data is ordered by time. However, the caret library allows for this by using a rolling window estimation method. 

Prepare for caret library
```{r}
set.seed(1)
#prepare parallel computing method
registerDoParallel(cores=6)
myTimeControl <- trainControl(method = "timeslice",
                              initialWindow = 200,
                              horizon = 10,
                              fixedWindow = TRUE,
                              #classProbs = TRUE, 
                              #summaryFunction = twoClassSummary,
                              allowParallel = TRUE,
                              savePredictions = "all")
```


LASSO/RIDGE with technicals (1), fundamentals, and sentiment desc
```{r}
#optimise using AIC and BIC
#Drop the index
DJIA.train$Index <- NULL
lasso.grid <- expand.grid(lambda=seq(0,1,by=0.05),alpha=1)
lasso.fit <- train(direction ~ .,
                    data = DJIA.train,
                    method = "glmnet",
                    metric = "Accuracy",
                    family = "binomial",
                    #preProcess = c("range"),
                    trControl = myTimeControl,
                    tuneGrid = lasso.grid)
lasso.pred <- predict(lasso.fit, DJIA.test)
confusionMatrix(lasso.pred, DJIA.test$direction)
mean(lasso.pred == DJIA.test$direction) 
```
We obtain an accuracy of only 46.7%


Lasso with technical (1) only

```{r}
lasso.grid1 <- expand.grid(lambda=seq(0,0.2,by=0.01),alpha=1)
lasso.fit1 <- train(direction ~ .,
                    data = DJIA.train.t1,
                    method = "glmnet",
                    metric = "Accuracy",
                    family = "binomial",
                    #preProcess = c("range"),
                    trControl = myTimeControl,
                    tuneGrid = lasso.grid1)
lasso.pred1 <- predict(lasso.fit1, DJIA.test.t1)
confusionMatrix(lasso.pred1, DJIA.test.t1$direction)
```
We obtain an accuracy of 49.48%

Lasso with technical (2) only
```{r}
lasso.grid2 <- expand.grid(lambda=seq(0,0.8,by=0.05),alpha=1)
lasso.fit2 <- train(direction ~ .,
                    data = DJIA.train.t2,
                    method = "glmnet",
                    metric = "Accuracy",
                    family = "binomial",
                    #preProcess = c("range"),
                    trControl = myTimeControl,
                    tuneGrid = lasso.grid2)
lasso.pred2 <- predict(lasso.fit2, DJIA.test.t2)
confusionMatrix(lasso.pred2, DJIA.test.t2$direction)
mean(lasso.pred2 == DJI.test2$direction)    
```
We obtain an accuracy of 57.39%


Lasso with fundamentals only
```{r}
lasso.fit.f <- train(direction ~ .,
                    data = DJI.train.f,
                    method = "glmnet",
                    metric = "ROC",
                    family = "binomial",
                    preProcess = c("range"),
                    trControl = myTimeControl,
                    tuneGrid = lasso.grid)
lasso.pred.f <- predict(lasso.fit.f, DJI.test.f)
confusionMatrix(lasso.pred.f, DJI.test.f$direction)
```

LASSO wiith sentiment only from SentimentAnalysis method
```{r}

```

LASSO with sentiment only from sentimentr method
```{r}

```


Random Forest
```{r}
#a quick way to find a good value for mtry
#bestMtry <- tuneRF(DJI.train[,2:ncol(DJI.train)], DJI.train$direction, stepFactor = 1.5, improve = 1e-5, ntree = 1000)
#Using caret to grid search
mtry <- sqrt(ncol(DJI.train))
rfgrid <- expand.grid(.mtry=mtry)
rf.fit <- train(direction ~ .,
                    data = DJI.train,
                    method = "rf",
                    metric = 'Accuracy',
                    preProcess = c("range"),
                    trControl = rf.control,
                    tuneGrid = rfgrid)
print(rf.fit)
rf.test <- predict(rf.fit, newdata = DJI.test)
confusionMatrix(rf.test, DJI.test$direction)
#Alternatively
tune_grid <- expand.grid(
  mtry = c(
    ncol(DJI.train)-1, # p
    ncol((DJI.train)-1)/ 3, # p / 3
    ceiling(sqrt(ncol(DJI.train))) # square root of p
  )
)
rf.control2 <-trainControl(method = "timeslice",
                              initialWindow = 32,
                              horizon = 12,
                              fixedWindow = FALSE,
                              number = 10,
                              search = "random",
                              classProbs = TRUE, 
                              allowParallel = TRUE,
                              repeats = 3)
rf.fit2 <- train(direction ~ .,
                    data = DJI.train,
                    method = "rf",
                    metric = 'Accuracy',
                    preProcess = c("range"),
                    trControl = rf.control2,
                    tuneGrid = tune_grid)
print(rf.fit2)
rf.test2 <- predict(rf.fit2, newdata = DJI.test)
confusionMatrix(rf.test2, DJI.test$direction)
```


SVM
```{r}
#First we find the optimal tuning parameter
svm.tune <- train(direction~.,
                  data = DJIA.train,
                  method = "svmRadial",   # Radial kernel
                  tuneLength = 9,					# 9 values of the cost function
                  #preProc = c("range"),  # Center and scale data
                  #metric="Accuracy",
                  trControl=myTimeControl)
svm.tune
svm.test <- predict(svm.tune, newdata = DJIA.test)
confusionMatrix(svm.test, DJIA.test$direction)
#we narrow the grid search
svm.grid <- expand.grid(sigma = c(0.25, .026, 0.027), C = c(7, 8, 9))
svm.tune2 <- train(direction~.,
                  data = DJIA.train,
                  method = "svmRadial",   # Radial kernel
                  tuneGrid = svm.grid,					# 9 values of the cost function
                  trControl=myTimeControl)
svm.test2 <- predict(svm.tune2, newdata = DJIA.test)
confusionMatrix(svm.test, DJIA.test$direction)
```
Using technical indicators 1
```{r}
svm.tune3 <- train(direction~.,
                  data = DJIA.train.t1,
                  method = "svmRadial",   # Radial kernel
                  tuneLength = 9,					# 9 values of the cost function
                  trControl=myTimeControl)
svm.tune3
svm.test <- predict(svm.tune3, newdata = DJIA.test.t1)
confusionMatrix(svm.test, DJIA.test.t1$direction, positive = "up")
varImp(svm.tune3)
#we narrow the grid search
svm.grid.t1 <- expand.grid(sigma = c(.040, .035, 0.045), C = c(12, 16, 20))
svm.t1 <- train(direction~.,
                  data = DJIA.train.t1,
                  method = "svmRadial",   # Radial kernel
                  tuneGrid = svm.grid.t1,					# 9 values of the cost function
                  trControl=myTimeControl)
svm.test.t1 <- predict(svm.t1, newdata = DJIA.test.t1)
confusionMatrix(svm.test.t1, DJIA.test.t1$direction)
```

SVM with technicals 2
```{r}
svm.tune4 <- train(direction~.,
                  data = DJIA.train.t2,
                  method = "svmRadial",   # Radial kernel
                  tuneLength = 9,					# 9 values of the cost function
                  trControl=myTimeControl)
svm.tune4
svm.test <- predict(svm.tune4, newdata = DJIA.test.t2)
confusionMatrix(svm.test, DJIA.test.t2$direction, positive = "up")
varImp(svm.tune4)
#we narrow the grid search
svm.grid.t2 <- expand.grid(sigma = c(.040, .035, 0.045), C = c(0.5, 0.25, 0.75))
svm.t2 <- train(direction~.,
                  data = DJIA.train.t2,
                  method = "svmRadial",   # Radial kernel
                  tuneGrid = svm.grid.t2,					# 9 values of the cost function
                  trControl=myTimeControl)
svm.test.t2 <- predict(svm.t2, newdata = DJIA.test.t2)
confusionMatrix(svm.test.t2, DJIA.test.t2$direction)
```

Random Forest
```{r}
rfGrid <- data.frame(mtry = c(4, 5, 6, 7, 8, 9, 10, 20, 31))
rf.fit <- train(direction ~ .,
                    data = DJIA.train,
                    method = "rf",
                    trControl = myTimeControl,
                    tuneGrid = rfGrid)
rf.fit
rfGrid <- data.frame(mtry = c(3:6))
rf.fit.1 <- train(direction ~ .,
                    data = DJIA.train,
                    method = "rf",
                    trControl = myTimeControl,
                    tuneGrid = rfGrid)
rf.fit.1$finalModel
varImp(rf.fit.1)
rf.test <- predict(rf.fit.1, newdata = DJIA.test)
confusionMatrix(rf.test, DJIA.test$direction)
```

Random Forest with t1
```{r}
rfGrid.t1 <- data.frame(mtry = c(4, 5, 6, 7, 8, 9, 10, 20, 31))
rf.tune.t1 <- train(direction ~ .,
                    data = DJIA.train.t1,
                    method = "rf",
                    trControl = myTimeControl,
                    ntree = 3000,
                    tuneGrid = rfGrid)
rf.test.t1 <- predict(rf.tune.t1, newdata = DJIA.test.t1)
confusionMatrix(rf.test.t1, DJIA.test.t1$direction)
rfGrid.t1 <- data.frame(mtry = c(2:13))
rf.t1 <- train(direction ~ .,
                    data = DJIA.train.t1,
                    method = "rf",
                    trControl = myTimeControl,
                    ntree = 3000,
                    tuneGrid = rfGrid)
rf.test.t1 <- predict(rf.t1, newdata = DJIA.test.t1)
confusionMatrix(rf.test.t1, DJIA.test.t1$direction)
```

Random forest with t2
```{r}
rfGrid.t2 <- data.frame(mtry = c(4, 5, 6, 7, 8, 9, 10, 20, 31))
rf.tune.t2 <- train(direction ~ .,
                    data = DJIA.train.t2,
                    method = "rf",
                    trControl = myTimeControl,
                    ntree = 3000,
                    tuneGrid = rfGrid)
rf.test.t2 <- predict(rf.tune.t2, newdata = DJIA.test.t2)
confusionMatrix(rf.test.t2, DJIA.test.t2$direction)
rfGrid.t2 <- data.frame(mtry = c(2:13))
rf.t2 <- train(direction ~ .,
                    data = DJIA.train.t2,
                    method = "rf",
                    trControl = myTimeControl,
                    ntree = 3000,
                    tuneGrid = rfGrid)
rf.test.t2 <- predict(rf.t2, newdata = DJIA.test.t2)
confusionMatrix(rf.test.t2, DJIA.test.t2$direction)
```


Neural net (full)
```{r}
nnet.grid <- expand.grid(.decay = c(0.5, 0.1), .size = c(5, 6, 7))
nnet.fit <- train(DJIA.train[,-1], 
                  DJIA.train$direction,
                  method = "nnet",
                  maxit = 1000, 
                  tuneGrid = nnet.grid) 
nnet.pred <- predict(nnet.fit, DJIA.test)
confusionMatrix(nnet.pred, DJIA.test$direction)
#alternate method
mlp.grid <- expand.grid(layer1 = 10, layer2=10, layer3=10)
nnet.fit2 <- train(x=DJIA.train[,-1], 
                  y=DJIA.train$direction,
                  method = "mlpML",
                  tuneGrid = mlp.grid) 
nnet.pred.2 <- predict(nnet.fit2, DJIA.test)
confusionMatrix(nnet.pred.2, DJIA.test$direction)
```

Neural net with t1
```{r}

```

